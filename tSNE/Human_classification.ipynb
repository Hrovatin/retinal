{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import random\n",
    "import scipy.io\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from numpy import arange\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "\n",
    "import importlib\n",
    "import tsne_functions\n",
    "importlib.reload(tsne_functions)\n",
    "from tsne_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import matplotlib as mpl\n",
    "import IPython\n",
    "mpl.rcParams['savefig.dpi'] = 300\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "IPython.display.set_matplotlib_formats('png','pdf', quality=100)\n",
    "pylab.rcParams['figure.figsize'] = (5.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/home/khrovatin/retinal/data/counts/'\n",
    "data_path_h='/home/khrovatin/retinal/data/human/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_data=pd.read_table(data_path+'passedQC_cellData.tsv',index_col=0)\n",
    "col_by_region=col_data.groupby('region')\n",
    "fov_cells=col_by_region.get_group('fov').index\n",
    "per_cells=col_by_region.get_group('per').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(data_path+'scaledata.h5','r') as file:\n",
    "    #As h5 file was saved in R it is imported as transposed\n",
    "    data_int=pd.DataFrame(file.get('integrated/matrix')[:file.get('integrated/matrix').shape[0],:])\n",
    "    data_int.columns=[name.decode() for name in file.get('integrated/rownames')]\n",
    "    data_int.index=[name.decode() for name in file.get('integrated/colnames')[:file.get('integrated/colnames').shape[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(data_path+'normalisedlog.h5','r') as file:    \n",
    "    data_norm=pd.DataFrame(file.get('ref/matrix')[:file.get('ref/matrix').shape[0],:])\n",
    "    data_norm.columns=[name.decode() for name in file.get('ref/rownames')]\n",
    "    data_norm.index=[name.decode() for name in file.get('ref/colnames')[:file.get('ref/colnames').shape[0]]]\n",
    "    \n",
    "    data_norm_h=pd.DataFrame(file.get('00012_NeuNM/matrix')[:file.get('00012_NeuNM/matrix').shape[0],:])\n",
    "    data_norm_h.columns=[name.decode() for name in file.get('00012_NeuNM/rownames')]\n",
    "    data_norm_h.index=[name.decode() for name in file.get('00012_NeuNM/colnames')[:file.get('00012_NeuNM/colnames').shape[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale for logistic regression\n",
    "data_norm=pd.DataFrame(scale(data_norm,with_std=False),index=data_norm.index,columns=data_norm.columns)\n",
    "data_norm_h=pd.DataFrame(scale(data_norm_h,with_std=False),index=data_norm_h.index,columns=data_norm_h.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_h=scipy.io.mmread('/share/LBI_share/public/retina/human snRNAseq data_10x_ChenLab_ZupanLab/humansn_10x_storage/00012_NeuNM_filtered_feature_bc_matrix/matrix.mtx.gz')\n",
    "counts_h=pd.DataFrame.sparse.from_spmatrix(counts_h).T\n",
    "counts_h.columns=pd.read_table('/share/LBI_share/public/retina/human snRNAseq data_10x_ChenLab_ZupanLab/humansn_10x_storage/00012_NeuNM_filtered_feature_bc_matrix/features.tsv.gz',header=None)[1]\n",
    "counts_h.index=pd.read_table('/share/LBI_share/public/retina/human snRNAseq data_10x_ChenLab_ZupanLab/humansn_10x_storage/00012_NeuNM_filtered_feature_bc_matrix/barcodes.tsv.gz',header=None)[0]\n",
    "counts_h.index=[idx.split('-')[0] for idx in counts_h.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicated gene symbols in human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some gene symbols are duplicated in the human data (see count below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated gene symbols among all human genes 91\n"
     ]
    }
   ],
   "source": [
    "genes_duplicated=[k for k,v in Counter(list(counts_h.columns)).items() if v > 1]\n",
    "print('Duplicated gene symbols among all human genes', len(genes_duplicated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genes_duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes=pd.read_table('/share/LBI_share/public/retina/human snRNAseq data_10x_ChenLab_ZupanLab/humansn_10x_storage/00012_NeuNM_filtered_feature_bc_matrix/features.tsv.gz',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for gene in genes_duplicated:\n",
    "#    print(genes[genes[1]==gene])\n",
    "    #print(counts_h.iloc[:,counts_h.columns==gene].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these ENS IDs point to deprecated genes/poorly characterized proteins. As their homology in macaque is uncertain based solely on gene symbols they are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retain variable genes with unique symbols and remove low quality cells from human counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11194, 2203) (156644, 2203)\n",
      "(11194, 2196) (156644, 2196)\n"
     ]
    }
   ],
   "source": [
    "print(data_norm_h.shape,data_norm.shape)\n",
    "\n",
    "for gene in genes_duplicated:\n",
    "    if gene in data_norm_h.columns:\n",
    "          data_norm_h=data_norm_h.drop(gene,axis=1)\n",
    "    if gene in data_norm.columns:\n",
    "          data_norm=data_norm.drop(gene,axis=1)\n",
    "\n",
    "print(data_norm_h.shape,data_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11245, 32738) (156644, 3605)\n",
      "(11194, 2196) (156644, 2196)\n"
     ]
    }
   ],
   "source": [
    "print(counts_h.shape,data_int.shape)\n",
    "counts_h=counts_h.loc[data_norm_h.index,data_norm.columns]\n",
    "data_int=data_int[data_norm.columns]\n",
    "print(counts_h.shape,data_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers=pd.read_csv('/home/khrovatin/retinal/data/markers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retained genes: 2196 ; marker genes: 142 ; intersection: 103\n"
     ]
    }
   ],
   "source": [
    "genes_retained=set(data_int.columns.values.copy())\n",
    "genes_marker=set(markers['Marker'])\n",
    "print('Retained genes:',len(genes_retained),'; marker genes:',len(genes_marker),'; intersection:',\n",
    "      len(genes_marker & genes_retained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data for classifier evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N train, validation, test: 125315 15664 15665\n"
     ]
    }
   ],
   "source": [
    "idx_shuffled=data_int.index.values.copy()\n",
    "shuffle(idx_shuffled)\n",
    "split1=int(len(idx_shuffled)*0.8)\n",
    "split2=int(len(idx_shuffled)*0.9)\n",
    "train=idx_shuffled[:split1]\n",
    "validation=idx_shuffled[split1:split2]\n",
    "test=idx_shuffled[split2:]\n",
    "print('N train, validation, test:',len(train),len(validation),len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tSNE embedding \n",
    "Uses macaque data obtained with Seurat integration workflow and raw human counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit tSNE and KNN\n",
    "Perform tSNE on macaque data and use KNN with default sklearn parameters for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_dicts={'region':{'per':'#478216','fov':'#944368'},\n",
    "             'cell_type':{'AC':'#bf7195','BC':'#b59a00','EpiImmune':'#75b05b',\n",
    "                          'HC':'#4d4d4d','PR':'#7a0606','RGC':'#1c5191'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tsne_train=data_int.loc[train,:]\n",
    "data_tsne_test=data_int.loc[test,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  tSNE per+fov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tSNE evaluation on per+fov\n",
    "Use training set to construct tSNE and classifier. Embed test set on tSNE and use it to evaluate classification. tSNE shows actual classes for both training (lower opacity) and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_data_int_eval=analyse_tsne(data1=data_tsne_train,data2=data_tsne_test,col_data=col_data,colour_dicts=colour_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tSNE on per+fov with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_int=make_tsne(data_int)\n",
    "#savePickle(data_path+'tSNE_integrated_sharedGenes.pkl',(tsne_int,data_int.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('By region')\n",
    "plot_tsne([tsne_int],[dict(zip(col_data.index,col_data['region']))],[ data_int.index], \n",
    "         legend=True,plotting_params = {'s': 0.2,'alpha':0.5},colour_dict=colour_dicts['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('By cell type')\n",
    "plot_tsne([tsne_int],[dict(zip(col_data.index,col_data['cell_type']))], [data_int.index],\n",
    "          legend=True,plotting_params = {'s': 0.2,'alpha':0.5},colour_dict=colour_dicts['cell_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('By more specific cell type; there are more types than colours')\n",
    "plot_tsne([tsne_int],[dict(zip(col_data.index,col_data['cell_types_fine']))], [data_int.index],\n",
    "          legend=False,plotting_params = {'s': 0.2,'alpha':0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tSNE fov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform tSNE on fov and construct classifier on it. Plots show fov data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_int_fov=make_tsne(data_int.loc[fov_cells,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('By region')\n",
    "plot_tsne([tsne_int_fov],[dict(zip(col_data.index,col_data['region']))],[ data_int.loc[fov_cells,:].index],\n",
    "          legend=True,plotting_params = {'s': 0.2,'alpha':0.5},colour_dict=colour_dicts['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('By cell type')\n",
    "plot_tsne([tsne_int_fov],[dict(zip(col_data.index,col_data['cell_type']))], [data_int.loc[fov_cells,:].index],\n",
    "          legend=True,plotting_params = {'s': 0.2,'alpha':0.5},colour_dict=colour_dicts['cell_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('By more specific cell type; there are more types than colours')\n",
    "plot_tsne([tsne_int_fov],[dict(zip(col_data.index,col_data['cell_types_fine']))], [data_int.loc[fov_cells,:].index],\n",
    "          legend=False,plotting_params = {'s': 0.2,'alpha':0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tSNE evaluation of fov with per\n",
    "Fov tSNE and classifier were used to plot and predict per data. Plots show fov tSNE (less opacity) with added per embedding, both using true (not predicted) classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_data_int_fov=analyse_tsne(data1=data_int.loc[fov_cells,:],data2=data_int.loc[per_cells,:],col_data=col_data,\n",
    "                               tsne1=tsne_int_fov,colour_dicts=colour_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tSNE per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform tSNE on per and construct classifier on it. Plots show per data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_int_per=make_tsne(data_int.loc[per_cells,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('By region')\n",
    "plot_tsne([tsne_int_per],[dict(zip(col_data.index,col_data['region']))],[ data_int.loc[per_cells,:].index],\n",
    "          legend=True,plotting_params = {'s': 0.2,'alpha':0.5},colour_dict=colour_dicts['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('By cell type')\n",
    "plot_tsne([tsne_int_per],[dict(zip(col_data.index,col_data['cell_type']))], [data_int.loc[per_cells,:].index],\n",
    "          legend=True,plotting_params = {'s': 0.2,'alpha':0.5},colour_dict=colour_dicts['cell_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('By more specific cell type; there are more types than colours')\n",
    "plot_tsne([tsne_int_per],[dict(zip(col_data.index,col_data['cell_types_fine']))], [data_int.loc[per_cells,:].index],\n",
    "          legend=False,plotting_params = {'s': 0.2,'alpha':0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tSNE evaluation of per with fov\n",
    "Per tSNE and classifier were used to plot and predict fov data. Plots show per tSNE (less opacity) with added fov embedding, both using true (not predicted) classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_data_int_per=analyse_tsne(data1=data_int.loc[per_cells,:],data2=data_int.loc[fov_cells,:],col_data=col_data,\n",
    "                               tsne1=tsne_int_per,colour_dicts=colour_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human embeding on tSNE\n",
    "Macaque data (reference), used for tSNE construction, is ploted with less opacity than added human counts data (added). Plot cell_type shows macaque cell types and predicted human cell types based on above described KNN clasifiers. cell_type plot shows human data points in larger size than macaque points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human counts data on tSNE from fov+per of macaque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_data_human=embed_tsne_new(data1=data_int,data2=counts_h,col_data1=col_data,tsne1=tsne_int,\n",
    "                                colour_dicts=colour_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePickle(data_path_h+'tsne_data_human.pkl',(pd.DataFrame(np.array(tsne_data_human[0]),index=data_int.index)\n",
    "                                              ,pd.DataFrame(np.array(tsne_data_human[1]),index=counts_h.index),\n",
    "                                          tsne_data_human[2],tsne_data_human[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human counts data on tSNE from fov of macaque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_data_human_fov=embed_tsne_new(data1=data_int.loc[fov_cells,:],data2=counts_h,col_data1=col_data,\n",
    "                                   tsne1=tsne_int_fov, colour_dicts=colour_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePickle(data_path_h+'tsne_data_human_fov.pkl',(pd.DataFrame(np.array(tsne_data_human_fov[0]),\n",
    "                                                               index=data_int.loc[fov_cells,:].index)\n",
    "                                                , pd.DataFrame(np.array(tsne_data_human_fov[1]),\n",
    "                                                               index=counts_h.index),\n",
    "                                          tsne_data_human_fov[2],tsne_data_human_fov[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human counts data on tSNE from per of macaque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_data_human_per=embed_tsne_new(data1=data_int.loc[per_cells,:],data2=counts_h,col_data1=col_data,\n",
    "                                   tsne1=tsne_int_per,colour_dicts=colour_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePickle(data_path_h+'tsne_data_human_per.pkl',(pd.DataFrame(np.array(tsne_data_human_per[0]),\n",
    "                                                               index=data_int.loc[per_cells,:].index)\n",
    "                                                , pd.DataFrame(np.array(tsne_data_human_per[1]),\n",
    "                                                               index=counts_h.index),\n",
    "                                          tsne_data_human_per[2],tsne_data_human_per[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human tSNE\n",
    "For comparison a tSNE made on human counts data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_human=make_tsne(data=counts_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePickle(data_path_h+'tsne_human_counts.pkl',(pd.DataFrame(np.array(tsne_human),index=counts_h.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne([tsne_human])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax regression\n",
    "Uses log normalised CPM data scaled to mean=0 and sd=1 for each gene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose regularisation parameter\n",
    "Uses 80% of data for fitting and 10% for validation (in below statistics named as test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lr_train=data_norm.loc[train,:]\n",
    "data_lr_validation=data_norm.loc[validation,:]\n",
    "data_lr_test=data_norm.loc[test,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_train_models=dict()\n",
    "for c in [0.001,0.01,0.1,1]:\n",
    "    print('\\n********* Regularisation parameter C:',round(c,3))\n",
    "    m=make_log_regression(data1=data_lr_train,data2=data_lr_validation,col_data=col_data,label='cell_type',\n",
    "                        logreg={'penalty':'l1','C':c,'random_state':0,'solver':'saga','n_jobs':30})\n",
    "    softmax_train_models[c]=m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make models and evaluate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c=0.01\n",
    "#softmax_params={'penalty':'l1','C':c,'random_state':0,'solver':'saga','n_jobs':30}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax per+fov\n",
    "Use training and test set to evaluate model, matching above tSNE+KNN classifier.\n",
    "Make model on whole (unpartitioned) dataset, used for later classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax_all_eval=make_log_regression(data1=data_lr_train,data2=data_lr_test,\n",
    "#                                     col_data=col_data,label='cell_type',logreg=softmax_params,\n",
    "#                                   log_reg=softmax_train_models[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax_all=LogisticRegression(**softmax_params).fit(data_norm, col_data.loc[data_norm.index,'cell_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax fov\n",
    "Create softmax model on fov data. Evaluate it with per data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax_fov=make_log_regression(data1=data_norm.loc[fov_cells,:],data2=data_norm.loc[per_cells,:],\n",
    "#                                     col_data=col_data,label='cell_type',logreg=softmax_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax per\n",
    "Create softmax model on per data. Evaluate it with fov data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax_per=make_log_regression(data1=data_norm.loc[per_cells,:],data2=data_norm.loc[fov_cells,:],\n",
    " #                                    col_data=col_data,label='cell_type',logreg=softmax_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax_human=predict(classifier=softmax_all,data=data_norm_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax_human_fov=predict(classifier=softmax_fov,data=data_norm_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax_human_per=predict(classifier=softmax_per,data=data_norm_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human classification summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified=pd.DataFrame([tsne_data_human[3],tsne_data_human_fov[3],tsne_data_human_per[3],\n",
    "                         softmax_human,softmax_human_fov,softmax_human_per],\n",
    "                       index=['knn_all','knn_fov','knn_per','softmax_all','softmax_fov','softmax_per']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_class=[]\n",
    "n_main_class=[]\n",
    "for row in classified.iterrows():\n",
    "    row=row[1]\n",
    "    n_main_class.append(row.value_counts().max())\n",
    "    main_class.append(row.value_counts().idxmax())\n",
    "classified['main_class']=main_class\n",
    "classified['N_main_class']=n_main_class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
